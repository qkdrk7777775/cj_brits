{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(X):\n",
    "    std=np.apply_along_axis(np.nanstd,0,X)\n",
    "    mean=np.apply_along_axis(np.nanmean,0,X)\n",
    "    z=(X-mean)/std\n",
    "    return [z,mean,std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\" \n",
    "    자료 로드 부분 입력\n",
    "    - forward\n",
    "      - deltas\n",
    "      - masks\n",
    "      - values\n",
    "    \n",
    "    - backward\n",
    "      - deltas\n",
    "      - masks\n",
    "      - values\n",
    "      \n",
    "    \"\"\" \n",
    "    def __init__(self):\n",
    "        super(MyDataset,self).__init__()\n",
    "        \n",
    "        df=pd.read_csv('../NA_30per_QC2_gamak1 (1).csv',parse_dates=True,na_values='NaN')\n",
    "        df['date']=pd.to_datetime(df['date'])\n",
    "\n",
    "        #full date generate\n",
    "        df=df.set_index('date')\n",
    "\n",
    "        #year\n",
    "        df=df[:'2019-01-01']\n",
    "        df=df['2018-01-01':]\n",
    "        temp=standardization(df)\n",
    "        df=temp[0]\n",
    "        self.mean_sd=temp[1],temp[2]\n",
    "        #dt_range = pd.date_range(min(df.index), max(df.index), freq='1H')\n",
    "        #na_date=set(dt_range)-set(df.index)\n",
    "        #df=pd.concat([df ,pd.DataFrame(columns=df.columns,index=na_date)],axis=0)\n",
    "        df=df.sort_index()\n",
    "        self.df=df\n",
    "        df_temp=df.copy()\n",
    "        df_temp=df_temp.fillna(method='ffill')\n",
    "        self.df_forwards=df_temp\n",
    "        \n",
    "        #forward\n",
    "        dic=dict()\n",
    "        for var in df.columns.values.tolist():\n",
    "            print(var)\n",
    "            temp=list()\n",
    "            temp.append(0)\n",
    "            for i in range(1,df.shape[0]):\n",
    "                temp_df=df[[var]][i:i+1]\n",
    "                if temp_df.notnull().values!=True:\n",
    "                    temp.append(i-temp[-1])\n",
    "                else:\n",
    "                    temp.append(temp[-1])\n",
    "            dic.update({var:temp})\n",
    "        \n",
    "        self.deltas=np.array(pd.DataFrame(dic))\n",
    "        #eval generate\n",
    "        df_temp=df.copy()\n",
    "        for seed in range(1,df.shape[1]):\n",
    "            np.random.seed(seed)\n",
    "            temp_idx=np.random.choice(df.shape[0],int(np.ceil(df.shape[0]*.1)))\n",
    "            df_temp[df_temp.columns[seed]][temp_idx]=np.nan\n",
    "        self.eval=df_temp\n",
    "        \n",
    "        #backward\n",
    "        df=df[::-1]\n",
    "        self.b_df=df\n",
    "        df_temp=df.copy()\n",
    "        df_temp=df_temp.fillna(method='ffill')\n",
    "        self.b_df_forwards=df_temp\n",
    "        dic=dict()\n",
    "        for var in df.columns.values.tolist():\n",
    "            print(var)\n",
    "            temp=list()\n",
    "            temp.append(0)\n",
    "            for i in range(1,df.shape[0]):\n",
    "                temp_df=df[[var]][i:i+1]\n",
    "                if temp_df.notnull().values!=True:\n",
    "                    temp.append(-(i-temp[-1]))\n",
    "                else:\n",
    "                    temp.append(temp[-1])\n",
    "            dic.update({var:temp})\n",
    "        self.back_deltas=np.array(pd.DataFrame(dic))\n",
    "\n",
    "        #eval generate\n",
    "        df_temp=df.copy()\n",
    "        for seed in range(1,df.shape[1]):\n",
    "            np.random.seed(seed)\n",
    "            temp_idx=np.random.choice(df.shape[0],int(np.ceil(df.shape[0]*.1)))\n",
    "            df_temp[df_temp.columns[seed]][temp_idx]=np.nan\n",
    "        self.b_eval=df_temp\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx>=50:\n",
    "            \n",
    "            data=dict()\n",
    "            data['forward']={'values':np.array(self.df)[(idx-50):(idx)],'masks':np.array(self.df.notnull()+0)[(idx-50):(idx)],\n",
    "                             'deltas':self.deltas[idx:(idx+50)],'forwards':np.array(self.df_forwards)[(idx-50):(idx)],\n",
    "                             'evals':np.array(self.eval)[(idx-50):(idx)],'eval_masks':np.array(self.eval.notnull()+0)[(idx-50):(idx)]}\n",
    "\n",
    "            data['backward']={'values':np.array(self.b_df)[(idx-50):(idx)],'masks':np.array(self.b_df.notnull()+0)[(idx-50):(idx)],\n",
    "                              'deltas':self.back_deltas[(idx-50):(idx)],'forwards':np.array(self.b_df_forwards)[(idx-50):(idx)],\n",
    "                             'evals':np.array(self.b_eval)[(idx-50):(idx)],'eval_masks':np.array(self.b_eval.notnull()+0)[(idx-50):(idx)]}\n",
    "            return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(recs):\n",
    "    if recs[0]!=None:\n",
    "        if all(list(map(lambda x: x!=None,recs))):\n",
    "            forward  = list(map(lambda x: x['forward'], recs))\n",
    "            backward = list(map(lambda x: x['backward'], recs))\n",
    "            if all(list(map(lambda x:len(x['deltas'])==50,forward))):\n",
    "                def to_tensor_dict(recs):\n",
    "                    values     =torch.FloatTensor(list(map(lambda r:r['values'],recs)))\n",
    "                    masks      =torch.FloatTensor(list(map(lambda r:r['masks'], recs)))\n",
    "                    deltas     =torch.FloatTensor(list(map(lambda r:r['deltas'],recs)))\n",
    "                    evals      =torch.FloatTensor(list(map(lambda r:r['evals'], recs)))\n",
    "                    eval_masks =torch.FloatTensor(list(map(lambda r:r['eval_masks'], recs)))\n",
    "\n",
    "                    return {'values':values, 'masks': masks, 'deltas': deltas, 'evals': evals, 'eval_masks': eval_masks} \n",
    "\n",
    "                ret_dict = {'forward': to_tensor_dict(forward), 'backward': to_tensor_dict(backward)}\n",
    "                return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth_top\n",
      "depth_middle\n",
      "depth_bottom\n",
      "wtemp_top\n",
      "wtemp_middle\n",
      "wtemp_bottom\n",
      "sal_top\n",
      "sal_middle\n",
      "sal_bottom\n",
      "do_top\n",
      "do_middle\n",
      "do_bottom\n",
      "density_top\n",
      "density_middle\n",
      "density_bottom\n",
      "dense_diff0\n",
      "dense_diff1\n",
      "depth_top\n",
      "depth_middle\n",
      "depth_bottom\n",
      "wtemp_top\n",
      "wtemp_middle\n",
      "wtemp_bottom\n",
      "sal_top\n",
      "sal_middle\n",
      "sal_bottom\n",
      "do_top\n",
      "do_middle\n",
      "do_bottom\n",
      "density_top\n",
      "density_middle\n",
      "density_bottom\n",
      "dense_diff0\n",
      "dense_diff1\n"
     ]
    }
   ],
   "source": [
    "Mydata=MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def to_var(var):\n",
    "    if torch.is_tensor(var):\n",
    "        var = Variable(var)\n",
    "        if torch.cuda.is_available():\n",
    "            var = var.cuda()\n",
    "        return var\n",
    "    if isinstance(var, int) or isinstance(var, float) or isinstance(var, str):\n",
    "        return var\n",
    "    if isinstance(var, dict):\n",
    "        for key in var:\n",
    "            var[key] = to_var(var[key])\n",
    "        return var\n",
    "    if isinstance(var, list):\n",
    "        var = map(lambda x: to_var(x), var)\n",
    "        return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.chdir('/home/ducj2/data/do_bottom/models')\n",
    "os.chdir('../')\n",
    "import models\n",
    "import utils\n",
    "import sys\n",
    "sys.path.append('./models')\n",
    "from models import brits_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter=torch.utils.data.DataLoader(Mydata,batch_size=32,collate_fn=collate_fn,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "\n",
    "    labels = []\n",
    "    preds = []\n",
    "\n",
    "    evals = []\n",
    "    imputations = []\n",
    "\n",
    "    save_impute = []\n",
    "    save_label = []\n",
    "\n",
    "    for idx, data in enumerate(val_iter):\n",
    "        if data!=None:\n",
    "            data = to_var(data)\n",
    "            ret = model.run_on_batch(data, None)\n",
    "\n",
    "            # save the imputation results which is used to test the improvement of traditional methods with imputed values\n",
    "            save_impute.append(ret['imputations'].data.cpu().numpy())\n",
    "\n",
    "            pred = ret['predictions'].data.cpu().numpy()\n",
    "\n",
    "            eval_masks = ret['eval_masks'].data.cpu().numpy()\n",
    "            eval_ = ret['evals'].data.cpu().numpy()\n",
    "            imputation = ret['imputations'].data.cpu().numpy()\n",
    "\n",
    "            evals += eval_[np.where(eval_masks == 1)].tolist()\n",
    "            imputations += imputation[np.where(eval_masks == 1)].tolist()\n",
    "\n",
    "            # collect test label & prediction\n",
    "            pred = pred\n",
    "            preds += pred.tolist()\n",
    "    preds = np.asarray(preds)\n",
    "#    print('AUC {}'.format(metrics.roc_auc_score(labels, preds)))\n",
    "\n",
    "    evals = np.asarray(evals)\n",
    "    imputations = np.asarray(imputations)\n",
    "\n",
    "    print('MAE', np.abs(evals - imputations).mean())\n",
    "    print('MRE', np.abs(evals - imputations).sum() / np.abs(evals).sum())\n",
    "    save_impute = np.concatenate(save_impute, axis=0)\n",
    "    np.save('./result_2018/{}_data'.format('brits_i'), save_impute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress epoch 0, 0.66%, average loss 75.28227233886719\n",
      " Progress epoch 0, 3.31%, average loss 30.494963073730467\n",
      " Progress epoch 0, 3.97%, average loss 38.569803873697914\n",
      " Progress epoch 0, 5.30%, average loss 38.2337064743042\n",
      " Progress epoch 0, 5.96%, average loss 42.35043165418837\n",
      " Progress epoch 0, 7.28%, average loss 41.345606023615055\n",
      " Progress epoch 0, 8.61%, average loss 41.007459787222054\n",
      " Progress epoch 0, 9.27%, average loss 43.628321511404856\n",
      " Progress epoch 0, 10.60%, average loss 42.94490671157837\n",
      " Progress epoch 0, 11.26%, average loss 44.84088718189913\n",
      " Progress epoch 0, 12.58%, average loss 44.13326986212479\n",
      " Progress epoch 0, 13.25%, average loss 45.76909637451172\n",
      " Progress epoch 0, 15.89%, average loss 41.09439945220947\n",
      " Progress epoch 0, 18.54%, average loss 37.86007499694824\n",
      " Progress epoch 0, 19.21%, average loss 39.21824751229122\n"
     ]
    }
   ],
   "source": [
    "#model = getattr(models, args.model).Model(108, 0.3, 1)\n",
    "model= brits_i.Model()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data_iter=torch.utils.data.DataLoader(Mydata,batch_size=32,collate_fn=collate_fn,shuffle=True)\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    run_loss = 0.0\n",
    "    for idx, data in enumerate(data_iter):\n",
    "        if data!=None:\n",
    "            data = to_var(data)\n",
    "            ret = model.run_on_batch(data, optimizer)\n",
    "            run_loss += ret['loss'].item()\n",
    "            print ('\\r Progress epoch {}, {:.2f}%, average loss {}'.format(epoch, (idx + 1) * 100.0 / len(data_iter), run_loss / (idx + 1.0)))\n",
    "    data_iter=torch.utils.data.DataLoader(Mydata,batch_size=32,collate_fn=collate_fn,shuffle=False)\n",
    "    evaluate(model, data_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2599, 50, 17)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/home/ai03/Desktop/nas/cj/jupyter/do_bottom/result_2018/brits_i_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
